ModelArguments:
  model_name_or_path: "t5-base"
  model_type: "t5"
  model_config: null
  tokenizer_name_or_path: "t5_qg_tokenizer"
  cache_dir: null
  label_smoothing: 0
  freeze_embeds: False
  project_name: "question-generation"
  onnx_mode: False

DataTrainingArguments:
  train_file_path: "./data/train_data_hl_t5.pt"
  valid_file_path: "./data/valid_data_hl_t5.pt"
  max_source_length: 512
  max_target_length: 32

TrainingArguments:
  report_to: null
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 1
  learning_rate: 3.0e-4
  weight_decay: 0.0001
  num_train_epochs: 5
  seed: 42
  remove_unused_columns: False
  evaluation_strategy: "steps"
  logging_steps: 2
  eval_steps: 100
  save_steps: 1000
  save_total_limit: 1
  load_best_model_at_end: True
  greater_is_better: False
  metric_for_best_model: "eval_loss"
  overwrite_output_dir: True
  do_train: True
  do_eval: True
  output_dir: "output/models/"
# optim: "adamw_ort_fused" enable this to support CUDA Optimizer for ONNX